\documentclass[14pt, fleqn, xcolor={dvipsnames, table}]{beamer}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext}
\usepackage{cite,enumerate,float,indentfirst}
\usepackage{cancel}

\usepackage{tikz}                   
\usetikzlibrary{shadows}

% \usepackage{enumitem}
% \setitemize{label=\usebeamerfont*{itemize item}%
%   \usebeamercolor[fg]{itemize item}
%   \usebeamertemplate{itemize item}}

\graphicspath{{images/}}

\usetheme{Madrid}
\usecolortheme{seahorse}
\renewcommand{\CancelColor}{\color{red}}

\setbeamercolor{footline}{fg=Blue!50}
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{}%
    И. Кураленок, Н. Поваров, Яндекс
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{}%
    Санкт-Петербург, 2014
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,right]{}%
  Стр. \insertframenumber{} из \inserttotalframenumber \hspace*{2ex}
  \end{beamercolorbox}}%
  \vskip0pt%
}
\newcommand\indentdisplays[1]{%
     \everydisplay{\addtolength\displayindent{#1}%
     \addtolength\displaywidth{-#1}}}
\newcommand{\itemi}{\item[\checkmark]}

\title{Машинное обучение: оценка методов обучения с учителем\\\small{}}
\author[]{\small{%
И.~Куралёнок,
Н.~Поваров}}
\date{}

\begin{document}

\begin{frame}
\maketitle
\small
\begin{center}
\vspace{-60pt}
\normalsize {\color{red}Я}ндекс \\
\vspace{80pt}
\footnotesize СПб, 2014
\end{center}
\end{frame}

\section{Постановка задачи и классификация способов оценки}
\begin{frame}{Задача на сегодня}
\emph{Задача:} Есть метод обучения и данные, на которых обучаемся. Хотим понять хорошо ли будет работать решающая функция на практике.\\

\flushleft{\em ``If you can't measure it, you can't improve it''} \\
\flushright{\textbf{—-- Lord Kelvin}} \\

\flushleft{\em ``Гораздо легче что-то измерить, чем понять, что именно вы измеряете.''} \\
\flushright{\textbf{—-- Джон Уильям Салливан}}
\end{frame}

\subsection{Классификация способов оценки}

\begin{frame}{Вспомним задачу МО}
$$
\arg \max_{F, B: \hat{F} = B(F)} A(\Gamma, \hat{F})
$$
\begin{itemize}
  \item $A$ --- цели эксплуатации (например деньги) на всей области работы $\Gamma$
  \item $B$ --- способ оптимизации, который реализуем
\end{itemize}

\end{frame}

\begin{frame}{Известные способы оценки}
Оценка эксплуатации (по принципу ``чёрного ящика''):
\begin{itemize}
  \item Оценка в боевых условиях (на пользователях)
  \item Кросс-валидация
  \item Повторные выборки
\end{itemize}
Оценка обучения (по принципу ``прозрачного ящика''):
\begin{itemize}
  \item VС-оценки
  \item PAC-Bayes bounds
  \item Оценки по Воронцову
\end{itemize}
\end{frame}

\section{Black box оценка}
\begin{frame}{Оценка в боевых условиях}
Как оценить, насколько пользователяю системы ``хорошо'' по его поведению?
Конкретная реализация зависит от области, но можно выделить типы:
\begin{itemize}
\item blind testing;
\item A/B тестирование (Abandonment Rate, MRR by long clicks, etc.);
\item подстроенные результаты (TDI, BI, etc.).
\end{itemize}
\footnotesize Мы можем долго-долго рассказывать байки в этом месте :).
\end{frame}

\subsection{Cross-validation}
\begin{frame}{Есть ли альтернативы}{Можно ли как-то обойтись без членовредительства?}
Не всегда ``боевые условия'' доступны:
\begin{itemize}
\item Люди не любят быть объектом экспериментирования
\item Качество эксперимента может быть сильно хуже продакшена
\item Количество одновременных экспериментов ограничено
\end{itemize}
$\Rightarrow$ Как бы нам эмулировать эксплуатацию? \\
\end{frame}

\begin{frame}{Cross-fold validation I}{Определение}
Разобьем множество $X$ на два $L$ и $T$ так, чтобы $L \cup T = X, L \cap T = \emptyset$ случайным образом.
Будем обучаться на одной половине а проверять результат обучения на другой.
\end{frame}

\begin{frame}{Cross-fold validation II}{Свойства}
\begin{description}
\itemindent=0em
\labelwidth=0em
\leftskip=-3em
  \item[\color{green}+] простой и надежный
  \item[\color{green}+] позволяет оценить распределение на множестве решений
  \item[\color{red}--] последовательные эксперименты зависимы
  \item[\color{red}--] используем мало данных для обучения
  \item[\color{red}--] непонятно как подбирать соотношения $\frac{|L|}{|T|}$
  \item[\color{red}--] результаты рассказывают про эксплуатацию с точностью до репрезентативности множества $X$
\end{description}
\end{frame}

\begin{frame}{Cross-fold validation III}{Способы реализации}
Можно организовать разными способами:
\begin{description}
\itemindent=0em
\labelwidth=0em
\leftskip=-3em
  \item[2-fold] обычно так и делаем
  \item[k-fold] когда очень боимся зависимости экспериментов, а данных много
  \item[Leave-one-out (LOO)] когда совсем мало данных
\end{description}
\end{frame}

\begin{frame}{Повторные выборки}
Сформируем 2 множества $L$ и $T$ так, что:
\begin{enumerate}
  \item $|L| = |T| = |X|$
  \item $l_i \sim U(X), t_i \sim U(X)$
\end{enumerate}
Будем считать, что эти 2 множества разные.
\begin{description}
\itemindent=0em
\labelwidth=0em
\leftskip=-3em
  \item[\color{green}+] используем полный объем выборки
  \item[\color{green}+] на больших объемах вариативность выбора огромна
  \item[\color{red}--] теперь еще и $T$ зависит от $L$ и как это учесть -- не ясно
\end{description}
$\Rightarrow$ можно применять только на больших объемах (>10k точек)
\end{frame}

\begin{frame}{Как принять решение по результатам CV/ПВ}
Не стоит забывать, что результаты CV/ПВ экспериментов всегда {\color{red} \em зависимы}. С точностью до этого алгоритм такой:
\small
\begin{enumerate}
  \item провести серию последовательных экспериментов;
  \item проверить
  $$H_0: \mathbb{E}\left(\mu(\hat{h}_A, T)\right) = \mathbb{E}\left(\mu(\hat{h}_B, T)\right)$$
  например с помощью парного WX-test'а;
  \item исследовать средний знак разницы $\mu(\hat{h}_A, T) - \mu(\hat{h}_B, T)$.
\end{enumerate}

\end{frame}

\section{Как можно повлиять на оценку}

\begin{frame}{}
\Large
Ввели понятия ``хорошо'' и ``плохо''\\
$\Rightarrow$ \bf Попробуем понять почему один метод работает лучше чем другой.
\end{frame}

\begin{frame}{Источник проблемы}
$$
\hat{h} = \arg \max_{h} \mathbb{E}_{\xi \sim \Gamma}\mu(y_{\xi}, h(x_{\xi}))
$$
Мы обучаемся на одном множестве, а работаем на другом. А что, если эти множества отличаются?
\end{frame}

\begin{frame}{Свойства выборки}
\flushleft{\em ``Иными словами, репрезентативная выборка представляет собой микрокосм, меньшую по размеру, но точную модель генеральной совокупности, которую она должна отражать.''}\\
\flushright{\textbf{--- Дж. Б. Мангейм, Р. К. Рич}}\\
\flushleft
Такого сложно достичь, поэтому хотим лишь ``несмещенности'' по параметрам обучения:
\small
$$\begin{array}{rl}
\hat{h} =& \arg \max_{h} \mathbb{E}_{\xi \sim D} \mu(y_{\xi}, h(x_{\xi})) \\
    =& \arg \max_{h} \mathbb{E}_{\xi \sim \Gamma} \mu(y_{\xi}, h(x_{\xi}))
\end{array}$$
\end{frame}

\begin{frame}{Как это выглядит в пространстве решений}
\centering
\includegraphics[width=0.65\textwidth]{bias_variance.png} 
\end{frame}

\begin{frame}{Понимаем в какой ситуации находимся}
\centering
\includegraphics[width=1.0\textwidth]{bias_error.png}
\end{frame}

\begin{frame}{Понимаем в какой ситуации находимся}
\centering
\includegraphics[width=1.0\textwidth]{bias_error_2.png}
\end{frame}

\begin{frame}{Что в какой ситуации делать}
  \begin{itemize}
    \item В решающей функции:
    \begin{itemize}
      \item усложнение может уменьшить bias
      \item упрощение может уменьшить variance
    \end{itemize}
    \item В пространстве задачи:
    \begin{itemize}
      \item Меньшее число факторов могут уменьшить variance
      \item Увеличение числа факторов может уменьшить bias      
    \end{itemize}
    \item Изменение целевой функции специальным образом может уменьшить variance
    \item Увеличение числа наблюдений может уменьшить variance
  \end{itemize}
\end{frame}

\section{Сложность модели}
\subsection{Пример с полиномами}

\begin{frame}{Сложность модели}{}
{\em Чем больше в модели параметров, тем большую информацию они несут.}\\
\flushright{\bf --- Ваш К.О.}
\flushleft\small
Какая бывает информация в параметрах:
\begin{itemize}
  \item про генеральную совокупность;
  \item про выборку;
  \item про random seed.
\end{itemize}
Если мы будем усложнять модель, соотношения информации будут двигаться.\\

\textbf{$\Rightarrow$ Хотим придумать рычажок, который контролирует сложность модели.}
\end{frame}

\begin{frame}{Семейство полиномов $p$-й степени}
Будем строить семейства решающих функций следующим образом:
\small
$$\begin{array}{l}
F(x, \beta^1) = {\beta_1^1}^Tx \\
F(x, \beta^2) = {\beta_1^2}^Tx + x^T{\beta_2^2}x\\
F(x, \beta^3) = {\beta_1^3}^Tx + x^T{\beta_2^3}x + \sum_i\sum_j\sum_k {\beta^3_3}_{ijk} x_i x_j x_k\\
etc.\\
\end{array}$$
Понятно, что $dim(\beta_i) < dim(\beta_{i+1})$.
\end{frame}

\subsection{VC-dimension}
\begin{frame}{Размерность Вапника-Червоненкиса}
\begin{definition}[ru.wikipedia.org]
$VC$-размерность класса функций $F$ --- наибольшее количество точек, которое может быть разделено функциями семейства, вне зависимости от конфигурации множества точек.
\end{definition}
\begin{tabular}{p{0.70\textwidth}p{0.25\textwidth}}
\colorbox{green!10}{
\includegraphics[width=0.20\textwidth]{100px-VC1.png}\hspace{2px}
\includegraphics[width=0.20\textwidth]{100px-VC2.png}\hspace{2px}
\includegraphics[width=0.20\textwidth]{100px-VC3.png}\hspace{1px}
} & \colorbox{red!10}{
\includegraphics[width=0.20\textwidth]{100px-VC4.png}\hspace{1px}
} \\
\end{tabular}
{\footnotesize картинки с en.wikipedia.org}
\end{frame}

\section{Виды ошибок}
\begin{frame}{Overfit vs. underfit}
\centering
\includegraphics[width=0.8\textwidth]{overfit_underfit.png} 
\end{frame}

\begin{frame}{Overfit vs. underfit определения}
\small
\begin{description}
\leftmargin=-5em
\itemindent=0em
\labelwidth=0em
\leftskip=-5em
  \item[Переобучение, переподгонка (overtraining, overfitting)] —-- нежелательное явление, возникающее при решении задач обучения по прецедентам, когда вероятность ошибки обученного алгоритма на объектах тестовой выборки оказывается существенно выше, чем средняя ошибка на обучающей выборке. 
  \item[Недообучение (underfitting)] --- нежелательное явление, возникающее при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно сложных моделей.
\end{description}
\flushright{\bf \normalsize--- machinelearning.ru}
\end{frame}

\begin{frame}{Как это выглядит в полиномах (underfit)}
\begin{center}
\includegraphics[width=0.9\textwidth]{300px-LsmRunge2.png}
\end{center}
{\footnotesize картинка с machinelearning.ru}
\end{frame}

\begin{frame}{Как это выглядит в полиномах (fit)}
\begin{center}
\includegraphics[width=0.9\textwidth]{300px-LsmRunge20.png}
\end{center}
{\footnotesize картинка с machinelearning.ru}
\end{frame}

\begin{frame}{Как это выглядит в полиномах (overfit)}
\begin{center}
\includegraphics[width=0.9\textwidth]{300px-LsmRunge40.png}
\end{center}
{\footnotesize картинка с machinelearning.ru}
\end{frame}

\section{Glass box оценка}

\begin{frame}{Принципы теоретической оценки}
Подход к оценке:
\begin{itemize}
  \item Загадаем какую-то функцию из одного класса
  \item По результатам работы загаданной функции, попробуем отгадать ее в том же классе, или в каком-то другом
  \item Сравним зависимость ошибки отгадывания от количества необходимых примеров
  \item Построим оценки на ошибку при заданном алгоритме отгадывания
\end{itemize}
\end{frame}

\begin{frame}{Механизм теоретической оценки}
Самый простой случай следующий:
\begin{itemize}
  \item Будем рассматривать пространство $\{0,1\}^n$ и распределение $D$ на этом пр-ве
  \item В рамках этого пространства зададим искомый сигнал (концепцию) $c \subset \{0,1\}^n$
  \item Рассмотрим гипотезу $h \subset \{0,1\}^n$ и введем ее ошибку:
  $$
  error(h) = \sum_{x \in h\Delta c} D(x)
  $$
\end{itemize}
$$\Rightarrow$$ будем исследовать какие ошибки достижимы при разных формах $c$ и $h$
\end{frame}

\begin{frame}{Критика теоретического подхода}
\begin{itemize}
  \item Не рассматриваем ошибки в данных
  \item Проводится оценка наихудшего сценария, что редко встречается на практике
\end{itemize}
\end{frame}


\subsection{VC-оценка и ее применение}
% \begin{frame}{Русские тоже что-то могут в ML :)}
% Владимир Наумович Вапник (NEC\footnote{Здесь и далее по данным ru.wikipedia.org}), \\
% Алексей Яковлевич Червоненкис (University of London). \\
% Разработали первую теорию по оценке переобучения в зависимости от класса решающих функций в 60-70е годы.
% \end{frame}

\begin{frame}{Оценка по методу Вапника-Червоненкиса I}
Хотим оценить $T(T)$ сверху по $T(L)$ и свойствам семейства решающих функций $H$.\\
$$
T(T) \ge T(L) - \sqrt{dim_{VC}(H)(\log(\frac{2m}{dim_{VC}(H)})+1)-\log(\frac{\delta}{4})\over m}
$$
с вероятностью $1-\delta$, $m = |L|$.
\end{frame}

\begin{frame}{Оценка по методу Вапника-Червоненкиса II}
\begin{center}
\includegraphics[height=0.6\textheight]{Herbrich2002_4-4.png}
\end{center}
{\footnotesize картинка с www.svms.org}
\end{frame}

\subsection{Оценка в слабой аксиоматике Воронцова}
\begin{frame}{Оценка в слабой аксиоматике Воронцова}
Воронцов Константин Вячеславович (ШАД в Москве, machinelearning.ru) написал докторскую диссертацию на тему \\
\center{\textit{``Комбинаторная теория надёжности обучения по прецедентам''}} \\
\flushleft в которой предложил интересную альтернативу VC-оценкам.
\end{frame}

\begin{frame}{Пару слов про KL-divergence}
\small
$$\begin{array}{ll}
\log(p(y)) &= \log(\frac{p(y,\theta)}{p(\theta|y)}) \\
&= \int q(\theta) \log \frac{p(y,\theta)}{p(\theta|y)} d\theta \\
&= \int q(\theta) \log \frac{p(y,\theta)}{p(\theta|y)}\frac{q(\theta)}{q(\theta)} d\theta \\
&= \int q(\theta) \left(\log \frac{q(\theta)}{p(\theta|y)} + \log \frac{p(y,\theta)}{q(\theta)}\right) d\theta \\
&= {\color{red}\left(\int q(\theta) log \frac{q(\theta)}{p(\theta|y)}d\theta\right)} + {\color{blue}\left(\int q(\theta) log \frac{p(y,\theta)}{q(\theta)} d\theta\right)} \\
\end{array}$$
Красная часть называется Kullback–Leibler divergence ($KL(p\|q)=D_{KL}(p\|q)$). Синяя---ELBO(Evidence lower bound).
\end{frame}

\begin{frame}{PAC обучаемость}{Таки Probably Approximately Correct :)}
Будем загадывать $c$ не просто так, а в каком-то классе $C$, и отгадывать $h$ в классе $H$
\begin{definition}
Если мы можем найти гипотезу в классе $H$, которая дает ошибку не более $\epsilon$ с вероятностью не более $1 - \delta$ за полиномиальное время, то назовем класс $C$ PAC обучаемым над классом $H$
\end{definition}
\end{frame}

\begin{frame}{Пара интересных результатов}
Если есть консистентный алгоритм, который обучает гипотезы из $H$ по сигналу из $C$, то для достижения ошибки $\epsilon$ с вероятностью $1 - \delta$, то ему понадобится не более:
$$
\frac{1}{\epsilon (1 - \sqrt{\epsilon})}\left(2 dim_{VC} (H) \log\frac{6}{\epsilon} + \log\frac{2}{\delta}\right)
$$
точек. Или если $|H| < \infty$, то:
$$
\frac{1}{\epsilon}\left(\log |H| + \log\frac{1}{\delta}\right)
$$

\end{frame}

\subsection{PAC-Bayes bounds I}
\begin{frame}{PAC-Bayes bounds I}
\small
Если подходить к вопросу не просто нахождением $\hat{h}$, а искать распределение над $H$, то к этому вопросу можно подходить последовательно (PAC-Bayes):

\begin{definition}[Оценка McAllester'а (1998)]
Введем априорное распределение над семейством решающих функций $h$. Тогда:
$$
T(\hat{h}, T) \ge T(\hat{h}, L) - \sqrt{log \frac{1}{p(\hat{h})} + log(\frac{1}{\delta}) \over 2m}
$$
с вероятностью не меньше $1-\delta$.
\end{definition}
\end{frame}

\begin{frame}{PAC-Bayes bounds II}
\small
Рассмотрим решение, как взвешивание между разными функциями семейства $F$.\footnote{Это такое байесовское решение, о котором мы поговорим в следующий раз} Тогда получится еще краше (современный вид):
$$
|\mu_\rho T(h_i, T) - \mu_\rho T(h_i, L)| \ge \sqrt{KL(\rho \| \pi) + log \frac{4n}{\delta} \over 2m - 1}
$$
с вероятностью не меньше $1-\eta$, где $\rho$ --- априорное распределение в семействе $F$, $\pi$ --- апостериорное.
\end{frame}

\section{Про неточные решения}
\begin{frame}{Соображения об точности решения}
До этого мы говорили о точных решениях. Но точность определения параметров обучения определяет количество информации в решении. \\
$\Rightarrow$ Не надо вычислять параметры решения до 100-го знака: sizeof(long double) >> sizeof(float) \\
~\\
В задачах итеративной оптимизации мы привыкли устремлять шаг к 0, что в случае ML приводит к большему variance решений.
\end{frame}

\section{Overfit on validate}
\begin{frame}{Как еще можно переобучиться?}
Будем долго и упорно подбирать метод обучения на фиксированном делении $L, T$:
$$
\max_{i} \left(\arg\max_{f \in F_i} T(f, L)\right)(T)
$$
Это же максимизация на всем множестве $L \cup T = X$! Называется такое overfit on validate. Что с этим делать? Исследовать
$$
\cancel{\max} \left(\arg \max_{i} \left(\arg\max_{f \in F_i} T(f, L)\right)(V)\right)(T)
$$
\end{frame}

\section{Где брать данные}
\begin{frame}{Где взять данные для экспериментов}
\begin{itemize}
  \item Реальные данные
  \begin{itemize}
    \item Поиск: РОМИП, TREC, Яндекс.ИМАТ, Yahoo LTRCh
    \item Pascal Challenge
    \item InnoCentive
    \item Kaggle
  \end{itemize}
  \item Синтетические данные (многомерный XOR)
  \item ``Загадки'': задумаем «хитрое» распределение и попробуем его отгадать
\end{itemize}
\end{frame}

\section{Домашнее задание}
\begin{frame}{Задача}
Дано:
\begin{itemize}
  \item $L$ = 1000 точек, полученных по правилу:
$$\begin{array}{l}
x \sim U (0,10] \\
y = ln(x)
\end{array}$$
  \item $T$ = 10000 реализаций $x$ для которых надо найти~$y$
\end{itemize}
Задача: найти решение в классе полиномов оптимальной степени $p$, наилучшим образом приближающий $y$ на $T$.

\end{frame}

\begin{frame}{Где брать домашние задания}
\begin{itemize}
  \item svn checkout http://ml-lections.googlecode.com/svn/trunk/ ml-lections-read-only
  \item Комитить не получится ;)
  \item Бонусом - лекции в tex.
  \item Лекции находятся в разных папках. В папке лекции есть папка homework.
  \item Помимо датасетов содержат файл howto.txt
  \item Вопросы: saintnik@yandex-team.ru
\end{itemize}

\end{frame}

\end{document} 
